{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage import feature\n",
    "from PIL import ImageOps\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ExifTags\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage import feature, morphology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anushan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def apply_kmeans(image_np, n_clusters=2):\n",
    "    pixels = image_np.reshape(-1, 3)\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(pixels)\n",
    "    labels = kmeans.labels_\n",
    "    mask = labels.reshape(image_np.shape[:2])\n",
    "    \n",
    "    leaf_cluster = np.argmin([np.linalg.norm(center - [0, 255, 0]) for center in kmeans.cluster_centers_])\n",
    "    binary_mask = (mask == leaf_cluster).astype(np.uint8)\n",
    "    \n",
    "    binary_mask = morphology.remove_small_objects(binary_mask.astype(bool), min_size=500).astype(np.uint8)\n",
    "    \n",
    "    return binary_mask\n",
    "\n",
    "def apply_lbp(image_np, radius=1, n_points=8):\n",
    "    gray_image = Image.fromarray(image_np).convert('L')\n",
    "    gray_np = np.array(gray_image)\n",
    "    lbp = feature.local_binary_pattern(gray_np, n_points, radius, method=\"uniform\")\n",
    "    return (lbp > np.percentile(lbp, 75)).astype(np.uint8)\n",
    "\n",
    "def exif_transpose(img):\n",
    "    if not hasattr(img, '_getexif') or img._getexif() is None:\n",
    "        return img\n",
    "\n",
    "    exif = img._getexif()\n",
    "    orientation = exif.get(0x0112, None) \n",
    "\n",
    "    transformations = {\n",
    "        2: Image.FLIP_LEFT_RIGHT,\n",
    "        3: Image.ROTATE_180,\n",
    "        4: Image.FLIP_TOP_BOTTOM,\n",
    "        5: Image.FLIP_LEFT_RIGHT,\n",
    "        6: Image.ROTATE_270,\n",
    "        7: Image.FLIP_LEFT_RIGHT,\n",
    "        8: Image.ROTATE_90\n",
    "    }\n",
    "\n",
    "    return img.transpose(transformations.get(orientation, None)) if orientation in transformations else img\n",
    "\n",
    "def resize_and_pad(img, target_size=(256, 256)):\n",
    "    \"\"\"Resizes the image maintaining its aspect ratio and pads the result to a target size.\"\"\"\n",
    "    bbox = ImageOps.crop(img, border=0).getbbox()\n",
    "    if not bbox:\n",
    "        return Image.new('RGB', target_size, (0, 0, 0))  # Return black image if no content\n",
    "    \n",
    "    cropped = img.crop(bbox)\n",
    "    ratio = min(target_size[0] / cropped.width, target_size[1] / cropped.height)\n",
    "    new_size = (int(cropped.width * ratio), int(cropped.height * ratio))\n",
    "    \n",
    "    # Resize while maintaining aspect ratio\n",
    "    img_resized = cropped.resize(new_size, Image.LANCZOS)\n",
    "    \n",
    "    # Pad to the target size\n",
    "    delta_w = target_size[0] - img_resized.width\n",
    "    delta_h = target_size[1] - img_resized.height\n",
    "    padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))\n",
    "    return ImageOps.expand(img_resized, padding, fill=(0, 0, 0))\n",
    "\n",
    "def prepare_image_for_prediction(image_path, save_dir):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        image = exif_transpose(image)\n",
    "        image_np = np.array(image)\n",
    "\n",
    "        kmeans_mask = apply_kmeans(image_np)\n",
    "        lbp_mask = apply_lbp(image_np)\n",
    "        combined_mask = np.logical_or(kmeans_mask, lbp_mask).astype(np.uint8)\n",
    "\n",
    "        combined_mask = morphology.opening(combined_mask, morphology.disk(3))\n",
    "        combined_mask = morphology.closing(combined_mask, morphology.disk(3))\n",
    "\n",
    "        segmented_color_image = image_np * np.stack([combined_mask]*3, axis=2)\n",
    "\n",
    "        if hasattr(image, \"_getexif\") and image._getexif() is not None:\n",
    "            exif_data = {ExifTags.TAGS[k]: v for k, v in image._getexif().items() if k in ExifTags.TAGS and isinstance(v, (bytes, str))}\n",
    "            exif_bytes = ExifTags.dump(exif_data)\n",
    "        else:\n",
    "            exif_bytes = None\n",
    "        \n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, f'prepared_{os.path.basename(image_path)}')\n",
    "        segmented_img = Image.fromarray(segmented_color_image)\n",
    "\n",
    "        if exif_bytes:\n",
    "            segmented_img.save(save_path, exif=exif_bytes)\n",
    "        else:\n",
    "            segmented_img.save(save_path)\n",
    "\n",
    "        # Resize and pad the segmented image to 2016x2016\n",
    "        with Image.open(save_path) as img:\n",
    "            new_img = resize_and_pad(img)\n",
    "            new_img.save(save_path)\n",
    "\n",
    "        return save_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "uploaded_image_path = \"D:\\\\BscSE\\\\Final Project\\\\HerbQuest\\\\software\\\\herbquest_backend\\\\prediction\\\\pred.jpg\"\n",
    "save_segmented_dir = \"D:\\\\BscSE\\\\Final Project\\\\HerbQuest\\\\software\\\\herbquest_backend\\\\prediction\\\\\"\n",
    "\n",
    "prepared_image_path = prepare_image_for_prediction(uploaded_image_path, save_segmented_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = load_model('D:\\BscSE\\Final Project\\HerbQuest\\software\\herbquest_backend\\model\\herbquest_model_256.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction Probabilities:\n",
      "ButterflyPea: 0.00%\n",
      "CommonWireweed: 0.00%\n",
      "CrownFlower: 0.00%\n",
      "GreenChireta: 0.00%\n",
      "HeartLeavedMoonseed: 0.00%\n",
      "HolyBasil: 0.00%\n",
      "IndianCopperLeaf: 0.00%\n",
      "IndianJujube: 0.00%\n",
      "IndianStingingNettle: 0.00%\n",
      "IvyGourd: 0.28%\n",
      "RosaryPea: 0.01%\n",
      "SmallWaterClover: 0.00%\n",
      "SpiderWisp: 99.71%\n",
      "SquareStalkedVine: 0.00%\n",
      "TrellisVine: 0.00%\n",
      "The predicted class is: 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "def get_prediction(model, prepared_image_path):\n",
    "\n",
    "    # Load the pre-trained model\n",
    "    # model = load_model('D:\\BscSE\\Final Project\\HerbQuest\\software\\herbquest_backend\\model\\herbquest_model_256.h5')\n",
    "\n",
    "    # uploaded_image_path = \"D:\\\\BscSE\\\\Final Project\\\\HerbQuest\\\\software\\\\herbquest_backend\\\\prediction\\\\pred.jpg\"\n",
    "    # save_segmented_dir = \"D:\\\\BscSE\\\\Final Project\\\\HerbQuest\\\\software\\\\herbquest_backend\\\\prediction\\\\\"\n",
    "    # prepared_image_path = prepare_image_for_prediction(uploaded_image_path, save_segmented_dir)\n",
    "\n",
    "    # Load the image\n",
    "    img = load_img(prepared_image_path, target_size=(256, 256))\n",
    "    \n",
    "    # Convert the PIL Image to a numpy array\n",
    "    img_array = img_to_array(img)\n",
    "    \n",
    "    # Normalize the image (this step may or may not be necessary based on your model training)\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "    # Expand dimensions to match the shape the model expects\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Get the model's prediction\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    # Get the highest-probability class label\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    predicted_confidence = np.max(predictions[0])\n",
    "\n",
    "    # Map the class label to the class name\n",
    "    class_names = [\n",
    "        'ButterflyPea',\n",
    "        'CommonWireweed',\n",
    "        'CrownFlower',\n",
    "        'GreenChireta',\n",
    "        'HeartLeavedMoonseed',\n",
    "        'HolyBasil',\n",
    "        'IndianCopperLeaf',\n",
    "        'IndianJujube',\n",
    "        'IndianStingingNettle',\n",
    "        'IvyGourd',\n",
    "        'RosaryPea',\n",
    "        'SmallWaterClover',\n",
    "        'SpiderWisp',\n",
    "        'SquareStalkedVine',\n",
    "        'TrellisVine'\n",
    "    ]\n",
    "\n",
    "    predicted_class_name = class_names[predicted_class]\n",
    "\n",
    "    # Display the prediction probabilities for each class\n",
    "    print(\"Prediction Probabilities:\")\n",
    "    for class_name, predicted_probability in zip(class_names, predictions[0]):\n",
    "        print(f\"{class_name}: {predicted_probability * 100:.2f}%\")\n",
    "\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# Use the function\n",
    "predicted_class = get_prediction(model, prepared_image_path)\n",
    "print(f\"The predicted class is: {predicted_class}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_image = prepare_image(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
